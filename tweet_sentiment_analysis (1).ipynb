{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples\n",
    "import nltk\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "train_pos=all_positive_tweets[:4000]\n",
    "train_neg=all_negative_tweets[:4000]\n",
    "test_pos=all_positive_tweets[4000:]\n",
    "test_neg=all_negative_tweets[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_pos+train_neg\n",
    "test_x=test_pos+test_neg\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y=np.append(np.ones((len(test_pos),1)),np.zeros((len(test_neg),1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string \n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    ct=[]\n",
    "    for t in tweets:\n",
    "        t=re.sub(r'@\\w*','',t)\n",
    "        t=re.sub(r'#','',t)\n",
    "        t=re.sub(r'http\\S+','',t)\n",
    "        t=re.sub(r'[$&\\n]\\w*','',t)\n",
    "        t=re.sub(r'[.*]','',t)\n",
    "#         t=re.sub(r'u','',t)\n",
    "#         t=re.sub(r'ur','',t)\n",
    "#         t=re.sub(r'[`^()-]','',t)\n",
    "        ct.append(t)\n",
    "    return ct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_stem_tweets(clean_tweets):\n",
    "    st=[]\n",
    "    tokenizer=TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
    "    stemmer=PorterStemmer()\n",
    "    sw=stopwords.words('english')\n",
    "    for t in clean_tweets:\n",
    "        tokens=tokenizer.tokenize(t)\n",
    "        stem_tweet=[]\n",
    "        for word in tokens:\n",
    "            if(word not in sw and word not in string.punctuation):\n",
    "                stem_word=stemmer.stem(word)\n",
    "                stem_tweet.append(stem_word)\n",
    "        st.append(stem_tweet)\n",
    "    return st\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_freq_table(stem_tweets,target):\n",
    "    freq={}\n",
    "    target=np.squeeze(target).tolist()\n",
    "    for y,tweet in zip(target,stem_tweets):\n",
    "        for word in tweet:\n",
    "            pair=(word,y)\n",
    "            if pair in freq:\n",
    "                freq[pair]+=1\n",
    "            else:\n",
    "                freq[pair]=1\n",
    "    return freq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features(stem_tweets,freq):\n",
    "    feature_matrix=[]\n",
    "    for t in stem_tweets:\n",
    "        t_features=[1]\n",
    "        pos=0\n",
    "        neg=0\n",
    "        for word in t:\n",
    "            try:\n",
    "                pos=pos+freq[(word,1)]\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                neg=neg+freq[(word,0)]\n",
    "            except:\n",
    "                None\n",
    "        t_features.append(pos)\n",
    "        t_features.append(neg)\n",
    "        feature_matrix.append(t_features)\n",
    "    return feature_matrix\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanx1=clean_tweets(train_x)\n",
    "stemx1=tok_stem_tweets(cleanx1)\n",
    "freq=gen_freq_table(stemx1,train_y)\n",
    "# freq\n",
    "x1=gen_features(stemx1,freq)\n",
    "cleanx2=clean_tweets(test_x)\n",
    "stemx2=tok_stem_tweets(cleanx2)\n",
    "x2=gen_features(stemx2,freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\programs\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\programs\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x1,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994375"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x1,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x2,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
